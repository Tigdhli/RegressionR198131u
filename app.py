# -*- coding: utf-8 -*-
"""Regression Assignment2 for R198131U.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UVVeYhiIrPJwVEUi84xjIpbHkg4sSC8e
"""



#from google.colab import drive

#drive.mount('/content/drive')

import pandas as pd
import numpy as np
import seaborn as sns
import scipy as stats
 
import statsmodels.api as sm
import matplotlib
import matplotlib.pyplot as plt
 
from sklearn import metrics
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
label_encoder = LabelEncoder()
 
sns.set(rc={"figure.figsize": (22 , 22)})
sns.set(style="white")

data = pd.read_csv('datasets_13996_18858_WA_Fn-UseC_-Telco-Customer-Churn.csv')

data.describe()

data['TotalCharges']=pd.to_numeric(data['TotalCharges'], errors = 'coerce')

data.describe()

data['TotalCharges']=data['TotalCharges'].fillna(value= np.mean(data['TotalCharges']))

"""BEGINNING OF QUESTION ZERO"""

from numpy import array
values = array(data['Churn'])
integer_encoded = label_encoder.fit_transform(values)
onehot_encoded = OneHotEncoder(sparse=False)
integer_encoded = integer_encoded.reshape(len(integer_encoded),1)
onehot_encoded = onehot_encoded.fit_transform(integer_encoded)

data_new= data.drop('customerID', axis =1)
#data_new.head(2)
data_test= pd.get_dummies(data_new)
#data_test
data_test['Churn']=label_encoder.fit_transform(values)
#data_test['Churn']

#Question 0 being done since start of code
#Using the given dataset extract the relevant features that can define a customer churn
data_new['Churn']=label_encoder.fit_transform(values)
data_new['Churn']

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
data.hist(bins=50, figsize=(20,15))
plt.show()

"""BEGINNING OF QUESTION ONE"""

#Question 1
#Using relevant mapping features show features which have the strongest correlation with churning.

plt.figure(figsize=(10,10))
plt.title('CORRELATION GRAPH', fontsize=20)
questionAns=data_test.corr()['Churn'].sort_values(ascending = False).plot(kind='bar',color='purple')
print(" ")
print(" ")
print(" ")
print(" ")
questionAns

corr_matrix = data_test.corr()
#corr_matrix

corr_matrix['Churn'].sort_values(ascending = False)

#QUESTION 2
#Using relevant mapping features show features which have the strongest correlation with churning.    

from pandas.plotting import scatter_matrix
attributes = ["Churn", "MonthlyCharges", "SeniorCitizen","TotalCharges","tenure"]
scatter_matrix(data_test[attributes], figsize=(12, 8))



"""BEGINNING OF QUESTION 2"""

#QUESTION 3
#Using the features in (i) define and train an Extreme Gradient Boosting “XGBOOST” model .      
# We will use the data frame where we had created dummy variables
y = data_test['Churn'].values
X = data_test.drop(columns = ['Churn'])

# Scaling all the variables to a range of 0 to 1
from sklearn.preprocessing import MinMaxScaler
features = X.columns.values
scaler = MinMaxScaler(feature_range = (0,1))
scaler.fit(X)
X = pd.DataFrame(scaler.transform(X))
X.columns = features

# Creating Train & Testing Data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)

# Running logistic regression model
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
result = model.fit(X_train, y_train)
from sklearn import metrics
prediction_test = model.predict(X_test)
# Printing the prediction accuracy
print (metrics.accuracy_score(y_test, prediction_test))

# To get the weights of all the variables
weights = pd.Series(model.coef_[0],index=X.columns.values)
print (weights.sort_values(ascending = False)[:20].plot(kind='bar'))

from sklearn.ensemble import RandomForestClassifier
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)
model_rf = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,
                                  random_state =50, max_features = "auto",
                                  max_leaf_nodes = 30)
model_rf.fit(X_train, y_train)

# Making predictions
prediction_test = model_rf.predict(X_test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99)

from sklearn.svm import SVC

model.svm = SVC(kernel='linear') 
model.svm.fit(X_train,y_train)
preds = model.svm.predict(X_test)

# Creating the Confusion matrix
from sklearn.metrics import classification_report, confusion_matrix  
print(confusion_matrix(y_test,preds))

"""BEGINNING OF QUESTION 3"""

#Extreme Gradient Boosting “XGBOOST” model

from xgboost import XGBClassifier
model = XGBClassifier()
model.fit(X_train, y_train)
preds = model.predict(X_test)
#EVALUATING MODEL'S ACCURACY AND CALCULATING AUC VALUE
metrics.accuracy_score(y_test, preds)

"""BEGINNING OF QUESTION 4"""

import pickle
with open('customer_chun.pkl', 'wb') as file:
  pickle.dump(preds, file)

import flask
import pickle
# Use pickle to load in the pre-trained model.
with open(f'customer_chun.pkl', 'rb') as f:
    model = pickle.load(f)
app = flask.Flask(__name__, template_folder='templates')
@app.route('/', methods=['GET', 'POST'])
def main():
  #["Churn", "MonthlyCharges", "SeniorCitizen","TotalCharges","tenure"]
    if flask.request.method == 'GET':
        return(flask.render_template('main.html'))
    if flask.request.method == 'POST':
        MonthlyCharges = flask.request.form['MonthlyCharges']
        SeniorCitizen = flask.request.form['SeniorCitizen']
        TotalCharges = flask.request.form['TotalCharges']
        tenure = flask.request.form['tenure']
        input_variables = pd.DataFrame([[MonthlyCharges , SeniorCitizen , TotalCharges , tenure ]],
                                       columns=["MonthlyCharges", "SeniorCitizen","TotalCharges","tenure"],
                                       dtype=float)
        prediction = model.predict(input_variables)[0]
        return flask.render_template('main.html',
                                     original_input={'MonthlyCharges':MonthlyCharges,
                                                     'SeniorCitizen':SenoirCitizen,
                                                     'TotalCharges':TotalCharges,
                                                     'tenure': tenure},
                                     result=prediction,
                                     )
if __name__ == '__main__':
    app.run(debug = False)

